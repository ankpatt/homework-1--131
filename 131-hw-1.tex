% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={pstat 131 hw 1},
  pdfauthor={Ankita Pattnaik},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{pstat 131 hw 1}
\author{Ankita Pattnaik}
\date{04/03/2022}

\begin{document}
\maketitle

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Machine Learning Main Ideas:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define supervised and unsupervised learning. What are the
  difference(s) between them?
\end{enumerate}

Supervised learning relies on the response variable when unsupervised
learning does not. That is the main difference between the two, the
factor of having a response variable. In supervised learning, each
predictor has a response or expected response when in unsupervised there
is a lack of response variable that would usually supervise the
analysis. You also do not 100\% know your error rate because the true
value is so ambiguous.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Explain the difference between a regression model and a classification
  model, specifically in the context of machine learning.
\end{enumerate}

The difference splits up the categorical methods of quantitative and
qualitative variables. Simply, quantitative or numerical variables are
categorized as regression problems and qualitative or descriptive
variables are categorized as classification models. In the context of
machine learning, it is important to distinguish which model to use so
that you can set up, or ``code'', the problem correctly for accurate
analysis. The textbook talks about how these models can be used in
K-nearest models, or boosting which are elaborated in further chapters.
(Page 28-29).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Name two commonly used metrics for regression ML problems. Name two
  commonly used metrics for classification ML problems.
\end{enumerate}

Two commonly used metrics for regression ML problems are, as discussed
in the lecture slides, logistic regression and random forests (tree
based regressions). Two commonly used metrics for classification ML
problems includes k-means clustering and Principal Component Analysis
(PCA), again, as mentioned in the slides.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  As discussed, statistical models can be used for different purposes.
  These purposes can generally be classified into the following three
  categories. Provide a brief description of each.
\end{enumerate}

Descriptive models: Choosing a model to best visually emphasize a trend
in the data. Ex: using a line on a scatterplot (From Slide 7
lecture\_day2)

Inferential models: Find out which features are significant. Aim to test
theories, (possibly) causal claims, and state relationships between the
outcomes \& predictors in the analysis.

Predictive models: Figure out what combo of features fits the best. Aim
to predict Y with minimum reducible error. This model does not focus on
hypothesis tests.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Predictive models are frequently used in machine learning, and they
  can usually be described as either mechanistic or empirically-driven.
  Answer the following questions. Define mechanistic. Define
  empirically-driven. How do these model types differ? How are they
  similar?
\end{enumerate}

Mechanistic means using ``theory to predict what will happen in the real
world''. Empirically-driven means studying ``real-world events to
develop a theory''. (Source: Google) They differ because one draws
conclusions on the current data set off previously analyzed data, while
the other comes to conclusions with the data set being analyzed. They
are similar because they both are means of analyzing data to help draw
conclusions. While one uses already proved theories, and the other comes
to conclusion on a theory, they both provide analysis and conclusions to
the data sets being studied.

In general, is a mechanistic or empirically-driven model easier to
understand? Explain your choice.

I would assume a mechanistic model is easier to understand because we
can make conclusions based off theories that have already been proven.
This will allow more accurate conclusions and analysis versus presumed
analysis. We can also compare how the theory has been applied to other
data sets for any variance or error analysis.

Describe how the bias-variance tradeoff is related to the use of
mechanistic or empirically-driven models.

The bias-variance tradeoff. Piazza note confirming we did not go over
this in class.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  A political candidate's campaign has collected some detailed voter
  history data from their constituents. The campaign is interested in
  two questions: Classify each question as either predictive or
  inferential. Explain your reasoning for each.
\end{enumerate}

Given a voter's profile/data, how likely is it that they will vote in
favor of the candidate? I would categorize this as predictive. We can
make conclusions based off the profile on what the voter's final vote
will be. The profiles can be seen as predictors and the final vote, the
response.

How would a voter's likelihood of support for the candidate change if
they had personal contact with the candidate? I would characterize this
as inferential because the contact they have with the candidate has the
power to influence the response in the analysis. There is a relationship
between the outcome and the predictor, as defined in the lecture slides.

Exploratory Data Analysis:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We are interested in highway miles per gallon, or the hwy variable.
  Create a histogram of this variable. Describe what you see/learn.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --
\end{verbatim}

\begin{verbatim}
## v tibble  3.1.6     v dplyr   1.0.8
## v tidyr   1.2.0     v stringr 1.4.0
## v readr   2.1.2     v forcats 0.5.1
## v purrr   0.3.4
\end{verbatim}

\begin{verbatim}
## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(}\StringTok{"mpg"}\NormalTok{)}

\KeywordTok{ggplot}\NormalTok{(mpg, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{hwy)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{fill=}\StringTok{"white"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Highway MPG histogram plot"}\NormalTok{,}\DataTypeTok{x=}\StringTok{"Highway MPG"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Frequency"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{131-hw-1_files/figure-latex/unnamed-chunk-1-1.pdf}

This histogram shows that most cars have a frequency of being 15-25 mpg
regarding highway miles per gallon.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a scatterplot. Put hwy on the x-axis and cty on the y-axis.
  Describe what you notice. Is there a relationship between hwy and cty?
  What does this mean?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(mpg, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{hwy, }\DataTypeTok{y=}\NormalTok{cty)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"City and Highway MPG"}\NormalTok{, }\DataTypeTok{x=}\StringTok{"Highway MPG"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"City MPG"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{131-hw-1_files/figure-latex/unnamed-chunk-2-1.pdf}

There seems to be a correlation between highway and city mileage in the
mpg dataset as the information under both categories present an upward
trend, implying that the mpg in city and highway average present
themselves in the same trend.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Make a bar plot of manufacturer. Flip it so that the manufacturers are
  on the y-axis. Order the bars by height. Which manufacturer produced
  the most cars? Which produced the least?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(mpg,}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{fct_infreq}\NormalTok{(manufacturer))) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{stat =} \StringTok{'count'}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{coord_flip}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{( }\DataTypeTok{x=}\StringTok{"Vehicle Name"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Number Made"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{131-hw-1_files/figure-latex/unnamed-chunk-3-1.pdf}

Lincoln produced the least cars while Dodge produced the most.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Make a box plot of hwy, grouped by cyl. Do you see a pattern? If so,
  what?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(mpg, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{group=}\NormalTok{cyl, }\DataTypeTok{x=}\NormalTok{hwy)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom_boxplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{( }\DataTypeTok{title=} \StringTok{"Highway Grouped by Cyl Boxplot"}\NormalTok{, }\DataTypeTok{x=}\StringTok{"Highway"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{131-hw-1_files/figure-latex/unnamed-chunk-4-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Use the corrplot package to make a lower triangle correlation matrix
  of the mpg dataset.
\end{enumerate}

Which variables are positively or negatively correlated with which
others? Do these relationships make sense to you? Are there any that
surprise you?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(corrplot)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## corrplot 0.92 loaded
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mpg<-}\KeywordTok{cor}\NormalTok{(mpg[}\KeywordTok{sapply}\NormalTok{(mpg,is.numeric)])}
\KeywordTok{corrplot}\NormalTok{(mpg, }\DataTypeTok{type=}\StringTok{"lower"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{131-hw-1_files/figure-latex/unnamed-chunk-5-1.pdf} It
seems that all relationships with themselves are very positively
correlated. We can see ``year'' and ``displ'' have really low, positive
correlation as well as ``cyl'' with ``year''. ``Cyl'' and ``displ'' also
have very high correlation alongside ``hwy'' and ``cty'' which we showed
in number 2 of this homework! We can see that ``cty'' and ``displ'',
``cty'' and ``cyl'', ``hwy'' and ``displ'', as well as ``hwy'' and
``cyl'' have very negative correlation. ``cty'' and ``year'' have very
little negative correlation and finally, ``hwy'' and ``year'' seem to
have no correlation. There are none that surprise me, as I do not know
much about cars, however it was cool to see the confirmation of how
number 2 is positively correlated.

\end{document}
