---
title: "pstat 131 hw 1"
author: "Ankita Pattnaik"
date: "04/03/2022"
output:
  html_document:
    df_print: paged
---
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Machine Learning Main Ideas: 

1. Define supervised and unsupervised learning. What are the difference(s) between them?


Supervised learning relies on the response variable when unsupervised learning does not. That is the main difference between the two, the factor of having a response variable. In supervised learning, each predictor has a response or expected response when in unsupervised there is a lack of response variable that would usually supervise the analysis. You also do not 100% know your error rate because the true value is so ambiguous. 


2. Explain the difference between a regression model and a classification model, specifically in the context of machine learning.


The difference splits up the categorical methods of quantitative and qualitative variables. Simply, quantitative or numerical variables are categorized as regression problems and qualitative or descriptive variables are categorized as classification models. In the context of machine learning, it is important to distinguish which model to use so that you can set up, or "code", the problem correctly for accurate analysis. The textbook talks about how these models can be used in K-nearest models, or boosting which are elaborated in further chapters. (Page 28-29).


3. Name two commonly used metrics for regression ML problems. Name two commonly used metrics for classification ML problems.


Two commonly used metrics for regression ML problems are, as discussed in the lecture slides, logistic regression and random forests (tree based regressions).
Two commonly used metrics for classification ML problems includes k-means clustering and Principal Component Analysis (PCA), again, as mentioned in the slides. 


4. As discussed, statistical models can be used for different purposes. These purposes can generally be classified into the following three categories. Provide a brief description of each.

Descriptive models: Choosing a model to best visually emphasize a trend in the data. Ex: using a line on a scatterplot (From Slide 7 lecture_day2)

Inferential models: Find out which features are significant. Aim to test theories, (possibly) causal claims, and state relationships between the outcomes & predictors in the analysis.

Predictive models: Figure out what combo of features fits the best. Aim to predict Y with minimum reducible error. This model does not focus on hypothesis tests. 


5. Predictive models are frequently used in machine learning, and they can usually be described as either mechanistic or empirically-driven. Answer the following questions.
Define mechanistic. Define empirically-driven. How do these model types differ? How are they similar?

Mechanistic means using "theory to predict what will happen in the real world". Empirically-driven means studying "real-world events to develop a theory". (Source: Google) They differ because one draws conclusions on the current data set off previously analyzed data, while the other comes to conclusions with the data set being analyzed. They are similar because they both are means of analyzing data to help draw conclusions. While one uses already proved theories, and the other comes to conclusion on a theory, they both provide analysis and conclusions to the data sets being studied. 

In general, is a mechanistic or empirically-driven model easier to understand? Explain your choice.

I would assume a mechanistic model is easier to understand because we can make conclusions based off theories that have already been proven. This will allow more accurate conclusions and analysis versus presumed analysis. We can also compare how the theory has been applied to other data sets for any variance or error analysis. 

Describe how the bias-variance tradeoff is related to the use of mechanistic or empirically-driven models.

The bias-variance tradeoff. Piazza note confirming we did not go over this in class.


6. A political candidate’s campaign has collected some detailed voter history data from their constituents. The campaign is interested in two questions: Classify each question as either predictive or inferential. Explain your reasoning for each.

Given a voter’s profile/data, how likely is it that they will vote in favor of the candidate? I would categorize this as predictive. We can make conclusions based off the profile on what the voter’s final vote will be. The profiles can be seen as predictors and the final vote, the response. 

How would a voter’s likelihood of support for the candidate change if they had personal contact with the candidate? I would characterize this as inferential because the contact they have with the candidate has the power to influence the response in the analysis. There is a relationship between the outcome and the predictor, as defined in the lecture slides.



Exploratory Data Analysis:

1. We are interested in highway miles per gallon, or the hwy variable. Create a histogram of this variable. Describe what you see/learn.

```{r}
library(ggplot2)
library(tidyverse)
data("mpg")

ggplot(mpg, aes(x=hwy)) + geom_histogram(color="black", fill="white") + labs(title="Highway MPG histogram plot",x="Highway MPG", y = "Frequency")
```

This histogram shows that most cars have a frequency of being 15-25 mpg regarding highway miles per gallon.


2. Create a scatterplot. Put hwy on the x-axis and cty on the y-axis. Describe what you notice. Is there a relationship between hwy and cty? What does this mean?

```{r}
ggplot(mpg, aes(x=hwy, y=cty)) + geom_point() + labs(title="City and Highway MPG", x="Highway MPG", y = "City MPG")
```

There seems to be a correlation between highway and city mileage in the mpg dataset as the information under both categories present an upward trend, implying that the mpg in city and highway average present themselves in the same trend. 


3. Make a bar plot of manufacturer. Flip it so that the manufacturers are on the y-axis. Order the bars by height. Which manufacturer produced the most cars? Which produced the least?

```{r}

ggplot(mpg,aes(x = fct_infreq(manufacturer))) + 
	geom_bar(stat = 'count') + 
	coord_flip() + labs( x="Vehicle Name", y = "Number Made")
```

Lincoln produced the least cars while Dodge produced the most. 


4. Make a box plot of hwy, grouped by cyl. Do you see a pattern? If so, what?

```{r}
ggplot(mpg, aes(group=cyl, x=hwy)) + 
    geom_boxplot() + labs( title= "Highway Grouped by Cyl Boxplot", x="Highway")
```


5. Use the corrplot package to make a lower triangle correlation matrix of the mpg dataset. 

Which variables are positively or negatively correlated with which others? Do these relationships make sense to you? Are there any that surprise you?

```{r}
library(corrplot)
mpg<-cor(mpg[sapply(mpg,is.numeric)])
corrplot(mpg, type="lower")
```
It seems that all relationships with themselves are very positively correlated. We can see "year" and "displ" have really low, positive correlation as well as "cyl" with "year". "Cyl" and "displ" also have very high correlation alongside "hwy" and "cty" which we showed in number 2 of this homework! We can see that "cty" and "displ", "cty" and "cyl", "hwy" and "displ", as well as "hwy" and "cyl" have very negative correlation. "cty" and "year" have very little negative correlation and finally, "hwy" and "year" seem to have no correlation. There are none that surprise me, as I do not know much about cars, however it was cool to see the confirmation of how number 2 is positively correlated. 